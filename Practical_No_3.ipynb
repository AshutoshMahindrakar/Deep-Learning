{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gzvunOC-k6w",
        "outputId": "f2946cdc-715c-42a3-8edd-ac8a1d8d2f6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
            "\u001b[1m35363/35363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Predicted: [('n02123045', 'tabby', 0.3382272), ('n02123159', 'tiger_cat', 0.1327969), ('n02124075', 'Egyptian_cat', 0.07096967)]\n"
          ]
        }
      ],
      "source": [
        "# Practical No 3\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16\n",
        "# We load the VGG16 model pretrained on the ImageNet dataset. This model is capable of classifying images into 1000 different categories.\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input, decode_predictions\n",
        "# Step 1: Load Pretrained Model (VGG16 in this case)\n",
        "model = VGG16(weights='imagenet', include_top=True)\n",
        "# Step 2: Preprocess Input Data\n",
        "img_path = '/content/ruby_01.webp' # Path to your input image\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "# Resize image to match VGG16 input size. We load an image from a file and preprocess it to match the input format expected by VGG16. This involves resizing the image to 224x224 pixels (the input size of VGG16) and applying preprocessing specific to VGG16.\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)\n",
        "# Step 3: Feed Data to the Model\n",
        "preds = model.predict(x)\n",
        "# Step 4: Interpret Predictions\n",
        "print('Predicted:', decode_predictions(preds, top=3)[0])\n",
        "# Output the top 3 predictions with probabilities\n",
        "# Example Output:\n",
        "# Predicted: [('n02504458', 'African_elephant', 0.82658225), ('n01871265','tusker', 0.1122357), ('n02504013', 'Indian_elephant', 0.061040461)]\n",
        "\n"
      ]
    }
  ]
}